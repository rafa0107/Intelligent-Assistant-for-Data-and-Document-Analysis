{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13bdecc",
   "metadata": {},
   "source": [
    "**# Importanto o Dataset e verificando o conteúdo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7709c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rafae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           issue_url  \\\n",
      "0  \"https://github.com/zhangyuanwei/node-images/i...   \n",
      "1     \"https://github.com/Microsoft/pxt/issues/2543\"   \n",
      "2  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
      "3  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
      "4  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
      "\n",
      "                                         issue_title  \\\n",
      "0  can't load the addon. issue to: https://github...   \n",
      "1  hcl accessibility a11yblocking a11ymas mas4.2....   \n",
      "2  issue 1265: issue 1264: issue 1261: issue 1260...   \n",
      "3  issue 1266: issue 1263: issue 1262: issue 1259...   \n",
      "4  issue 1288: issue 1285: issue 1284: issue 1281...   \n",
      "\n",
      "                                                body  \n",
      "0  can't load the addon. issue to: https://github...  \n",
      "1  user experience: user who depends on screen re...  \n",
      "2  ┆attachments: <a href= https:& x2f;& x2f;githu...  \n",
      "3  gitlo = github x trello\\n---\\nthis board is no...  \n",
      "4  ┆attachments: <a href= https:& x2f;& x2f;githu...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\Desktop\\Portifolio\\AI_ASSISTANT_GITHUB\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rafae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords') #carrego stopwrds para filtragem NLP\n",
    "\n",
    "# Adiciona o caminho da pasta onde o arquivo 'dataset.py' está localizado\n",
    "# Isso pula a necessidade de mencionar a pasta com hífen no import\n",
    "caminho_raw = os.path.abspath(os.path.join('..', 'data', 'raw'))\n",
    "if caminho_raw not in sys.path:\n",
    "    sys.path.append(caminho_raw)\n",
    "\n",
    "from dataset import carregar_dados\n",
    "\n",
    "df = carregar_dados()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010a67a",
   "metadata": {},
   "source": [
    "**Processamento e limpeza dos dados**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427d4c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média de palavras em url: 1.0, em title: 5.459, em body: 28.4455\n",
      "Resultados para 'issue_url':\n",
      "- Valores Nulos (NaN): 0\n",
      "- Textos Vazios/Espaços: 0\n",
      "Resultados para 'clean_title':\n",
      "- Valores Nulos (NaN): 0\n",
      "- Textos Vazios/Espaços: 99\n",
      "Resultados para 'clean_body':\n",
      "- Valores Nulos (NaN): 0\n",
      "- Textos Vazios/Espaços: 11\n",
      "Palavras mais frequentes em titles: [('issu', 352), ('add', 151), ('bug', 137), ('found', 79), ('error', 49), ('test', 43), ('use', 39), ('api', 39), ('help', 34), ('fix', 34), ('new', 33), ('need', 26), ('log', 24), ('run', 23), ('list', 22), ('get', 20), ('set', 19), ('line', 17), ('typo', 17), ('task', 16)]\n",
      "Palavras mais frequentes em body: [('close', 1244), ('add', 1102), ('issues', 927), ('columns', 714), ('list', 585), ('comment', 558), ('column', 542), ('trello', 529), ('update', 396), ('default', 387), ('settings', 378), ('via', 376), ('sync', 373), ('move', 369), ('custom', 367), ('board', 358), ('card', 357), ('attachments', 355), ('cards', 353), ('matisiekpl', 352)]\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..', 'data', 'raw')))\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'data', 'processed')))\n",
    "\n",
    "\n",
    "from dataset import verifica_vazios, verifica_frequentes\n",
    "from data_processing import clean_text\n",
    "\n",
    "df[\"clean_title\"] = df[\"issue_title\"].apply(clean_text)\n",
    "df[\"clean_body\"] = df[\"body\"].apply(clean_text)\n",
    "\n",
    "\n",
    "media_palavras_url = df[\"issue_url\"].str.split().str.len().mean()\n",
    "media_palavras_title = df[\"clean_title\"].str.split().str.len().mean()\n",
    "media_palavras_body = df[\"clean_body\"].str.split().str.len().mean()\n",
    "\n",
    "print(f\"Média de palavras em url: {media_palavras_url}, em title: {media_palavras_title}, em body: {media_palavras_body}\")\n",
    "\n",
    "url_vazio = verifica_vazios(df,\"issue_url\")\n",
    "titles_vazio = verifica_vazios(df,\"clean_title\")\n",
    "body_vazio = verifica_vazios(df,\"clean_body\")\n",
    "\n",
    "palavras_frequentes_titles = verifica_frequentes(df,\"clean_title\", 20)\n",
    "print(f\"Palavras mais frequentes em titles: {palavras_frequentes_titles}\")\n",
    "palavras_frequentes_body = verifica_frequentes(df,\"clean_body\", 20)\n",
    "print(f\"Palavras mais frequentes em body: {palavras_frequentes_body}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68051a23",
   "metadata": {},
   "source": [
    "\n",
    "   **Análise descritiva dos dados processados**\n",
    "\n",
    "- Média de palavras para entender quantos tokens irão ser processados pela LLM\n",
    "    - Quantidade de células vazias em todas as colunas\n",
    "        - não teve resultado de células vazias, todas preenchidas\n",
    "    - Títulos - tamanhos médio de 5,4 palavras\n",
    "    - Body - Aproximadamente 28 palavras\n",
    "- Ideal para:\n",
    "    - Embeddings\n",
    "    - Chunking Leve\n",
    "    - RAG Eficiente(baixo custo e boa semântica)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d86188",
   "metadata": {},
   "source": [
    "**Criação de Texto final**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4683ea7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 805.08it/s, Materializing param=pooler.dense.weight]                               \n",
      "BertModel LOAD REPORT from: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>load addon issue error lib libc version glibc ...</td>\n",
       "      <td>load addon issue error lib libc version glibc ...</td>\n",
       "      <td>Title: load addon issue error lib libc version...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hcl accessibility yblocking ymas mas hcl makec...</td>\n",
       "      <td>user experience user depends screen reader get...</td>\n",
       "      <td>Title: hcl accessibility yblocking ymas mas hc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>issue issue issue issue issue issue issue issu...</td>\n",
       "      <td>attachments github com matisiekpl czekolada is...</td>\n",
       "      <td>Title: issue issue issue issue issue issue iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>issue issue issue issue issue issue issue issu...</td>\n",
       "      <td>gitlo github trello board linked update issue ...</td>\n",
       "      <td>Title: issue issue issue issue issue issue iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>issue issue issue issue issue issue issue issu...</td>\n",
       "      <td>attachments github com matisiekpl czekolada is...</td>\n",
       "      <td>Title: issue issue issue issue issue issue iss...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title  \\\n",
       "0  load addon issue error lib libc version glibc ...   \n",
       "1  hcl accessibility yblocking ymas mas hcl makec...   \n",
       "2  issue issue issue issue issue issue issue issu...   \n",
       "3  issue issue issue issue issue issue issue issu...   \n",
       "4  issue issue issue issue issue issue issue issu...   \n",
       "\n",
       "                                          clean_body  \\\n",
       "0  load addon issue error lib libc version glibc ...   \n",
       "1  user experience user depends screen reader get...   \n",
       "2  attachments github com matisiekpl czekolada is...   \n",
       "3  gitlo github trello board linked update issue ...   \n",
       "4  attachments github com matisiekpl czekolada is...   \n",
       "\n",
       "                                          final_text  \n",
       "0  Title: load addon issue error lib libc version...  \n",
       "1  Title: hcl accessibility yblocking ymas mas hc...  \n",
       "2  Title: issue issue issue issue issue issue iss...  \n",
       "3  Title: issue issue issue issue issue issue iss...  \n",
       "4  Title: issue issue issue issue issue issue iss...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#criação de nova coluna para texto final que será direcionado ao embedding\n",
    "df[\"final_text\"] = (\n",
    "    \"Title: \" + df[\"clean_title\"] +\n",
    "    \". Body: \" + df[\"clean_body\"]\n",
    ")\n",
    "\n",
    "#carregando o modelo que será usado, modelo rápido e leve para projeto OBS: Uso da CPU pois GPU esta ultrapassada para o modelo\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\", device=\"cpu\") #usando o paraphrasal para poder perguntar em portugues\n",
    "df[[\"clean_title\", \"clean_body\", \"final_text\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c24c0a4",
   "metadata": {},
   "source": [
    "**Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74f18f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 63/63 [00:13<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#listando o texto final em variavel para ser codificada\n",
    "texts = df[\"final_text\"].tolist()\n",
    "\n",
    "#realização do embedding pelo modelo escolhido\n",
    "embeddings = model.encode( \n",
    "    texts,\n",
    "    show_progress_bar= True\n",
    ")\n",
    "\n",
    "#criação do array em np \n",
    "embeddings = np.array(embeddings)\n",
    "print(embeddings.shape)\n",
    "\n",
    "#persistindo os dados em formato npy e csv para nao necessitar de conversao novamente\n",
    "np.save(\"embeddings.npy\",embeddings)\n",
    "df.to_csv(\"issue_processed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f82ff1",
   "metadata": {},
   "source": [
    "**Busca Semântica**\n",
    "\n",
    "- Primeiramente utilizarei busca ingênua para este caso, mais rápido e ideal para projetos pequenos.\n",
    "    - será utilizado semelhança de cossenos, variância de -1 a 1, sendo 1 o mais próximo.\n",
    "    - comparação de vetores do embedding, modelo utilizado de dimensão 384\n",
    "- Após implementado e projeto funconando, irei dar updgrade para utilizar índice vetorial\n",
    "- Devido a arquitetura proposta relacionado aos tipos de perguntas para o Chatbot, será implementado:\n",
    "    - Busca semântica\n",
    "    - Top k\n",
    "    - Limiar de similiaridade\n",
    "    Dessa forma será possível a resposta de perguntas analtícas e explicativas, não somente localizadoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ddcf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #ler diretamente esta célula sem precisar converter novamente os arquivos no embedding\n",
    "import numpy as np\n",
    "\n",
    "embeddings = np.load(\"embeddings.npy\")\n",
    "df = pd.read_csv(\"issue_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142573a2",
   "metadata": {},
   "source": [
    "**Exemplo de pergunta e formato para query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b58c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n",
      "[ 460 1670  427 ...  499 1006 1532]\n",
      "[1532 1006  499 1705  361  875 1930 1685  451  706 1799 1368 1226 1707\n",
      " 1659  582  782 1717 1023  632]\n",
      "0.7127585\n"
     ]
    }
   ],
   "source": [
    "from semantic_search import encode_query, cosine_similiarity_func\n",
    "\n",
    "pergunta = \"Quais sao os erros mais registrados no documento?\"\n",
    "query = encode_query(model, [pergunta])\n",
    "#print(query.shape)\n",
    "\n",
    "scores = cosine_similiarity_func(query,embeddings)\n",
    "scores = scores.flatten()\n",
    "scores_ordenados = np.argsort(scores)\n",
    "print(scores.shape)\n",
    "print(scores_ordenados)\n",
    "\n",
    "#fazendo busca top_k, depois refatorar montando em funcoes definidas\n",
    "# Atualizar o Readme e usar o topk como parametro para busca ao refatorar “Utilizamos top-k dinâmico para balancear cobertura semântica e precisão.”\n",
    "top_k = 20\n",
    "top_indices = scores_ordenados[-top_k:][::-1] #quero buscar os ultimos 20 valores e ordena-los em sequência maior para menor, pois np.arg retorna ordem crescente\n",
    "print(top_indices)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2040c41",
   "metadata": {},
   "source": [
    "**Implementando Limiar de similaridade**\n",
    "\n",
    " - Utilizei um limiar de similaridade cosseno ajustado empiricamente para garantir que apenas documentos semanticamente relevantes sejam utilizados como contexto para a LLM, reduzindo ruído e alucinação.\n",
    " - A princípio foi definido padrão = 0.30, após verifiquei de forma empirica os melhores valores para retornar respostas completas sem interferências de dados fora do padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "808f1706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'indice': np.int64(1532), 'score': np.float32(0.7127585), 'text': 'Title: add readme. Body: holofart release soon'}, {'indice': np.int64(1006), 'score': np.float32(0.7078291), 'text': 'Title: css html. Body: peab tama sti telefonist fikseeritud suurused peaksid asenduma ekraani suhtes lemine bar peab olema loetud hest php lehest konsuulteeri kasv lauriga lemisel baril peab olema ike koht kuhu tuleb avatar parem serv kuhu peale klikkides tuleb men kus vajalikud kaskutaja asjad veel kord lisapostitus profiil seaded logi lja eelmisega seoes vaja luua uus vaade mis kasutab sama css mis kujutaks kasutaja profiili vaade mis pole saadaval kui pole sisse logitud seal siis lihtsalt sul vaja luua keskse koha kuhu heb kasutaja avatar siis koha selle kuhu hevad kasutaja andmed avatarist leval iks olla kasutajanimi allpool email millal registreerus hetkel rohkem midagi pole vaja siis veel allpool selles iks olla valmiskoht kasutaja postituste nimekirja laadimiseks sinu asi siin hetkel vaid kujundust luua mingit loogikat taha pole vaja panna veel postituste lehel peal olema tekst pildi mber igal pool mitte vaid paremal postituste lehel postituste rval peab olema reitingu kast funktsionaalsust lge pole vaja panna esitamist htaeg dal hiljemalt'}, {'indice': np.int64(499), 'score': np.float32(0.7061278), 'text': 'Title: add gui. Body: would like suggest menu opens command bsadmingui nickname menu teleport player island lock unlock island lot things player island'}, {'indice': np.int64(1705), 'score': np.float32(0.7029323), 'text': 'Title: dkim ses. Body: terraform version terraform expected behavior look like aws provider allows generate dkim settings domain references'}, {'indice': np.int64(361), 'score': np.float32(0.7005524), 'text': 'Title: module vydiarnfileuploader requires main queue setup since overrides init implement requiresmainqueuesetup future release react native default initializing native modules background thread unless explicitly opted. Body: module vydiarnfileuploader requires main queue setup since overrides init implement requiresmainqueuesetup future release react native default initializing native modules background thread unless explicitly opted'}, {'indice': np.int64(875), 'score': np.float32(0.6995692), 'text': 'Title: realdonaldtrump obamacare premiums going predicting two years obamacare owned democrats disaster worry even though dems want obstruct repeal amp replace right tax cuts. Body: realdonaldtrump obamacare premiums going predicting two years obamacare owned democrats disaster worry even though dems want obstruct repeal amp replace right tax cuts via twitter november'}, {'indice': np.int64(1930), 'score': np.float32(0.697529), 'text': 'Title: mapa sin npc. Body: tierras altas crepusculares tiene ningun npc'}, {'indice': np.int64(1685), 'score': np.float32(0.69693244), 'text': 'Title: crs design. Body: main interface icommandhandler renamed irequesthandler support commands events longer returns result task obviously csharp public interface irequesthandler task handleasync request icommandcontext context enforces treat impacts command like pure events thoughts really want crs still offers way return synchronous results command left usage simple rest like interactions'}, {'indice': np.int64(451), 'score': np.float32(0.6959572), 'text': 'Title: bch btc. Body: hello silent register bch writes wrong address pool system asks correct address coins get btc thank'}, {'indice': np.int64(706), 'score': np.float32(0.6956311), 'text': 'Title: hdr sdr. Body: hello sure question feature request something wrong trying convert hdr video smpte mastering display color volume side data availabe sdr either right got hacky solution working consists converting hlg use backward compatible features hlg display sdr however also tried fiddling nominal peak luminance approximate gamma parameters control conversion found manually choosing good peak luma gives considerable results without clipping artefact mentioned another thread guess questions still valid zimg hdr hdr sdr hdr viceversa know way automatically select good peak luma hoping could reuse parameter mastering display side data disabling approximate gamma computation help task thank insights give releasing zimg source code'}, {'indice': np.int64(1799), 'score': np.float32(0.6952965), 'text': 'Title: gmres issues. Body: docstring sparse iterative solver scipy sparse linalg isolve gmres following issues callback argument fact residual vector residual norm tol argument seems stoptest fortran function uses relative test right hand side norm moreover seems preconditioned residual used test might related call gmres sometimes small maxiter return found solution maxiter seems return initial guess maxiter return found solution example residual norm printed using callback preconditioning maxiter sfepy nls iter residual rel sfepy iterative iteration sfepy iterative iteration sfepy iterative gmres convergence number iterations sfepy nls iter residual rel last line reports new residual norm first line maxiter sfepy nls iter residual rel sfepy iterative iteration sfepy iterative iteration sfepy iterative gmres convergence number iterations sfepy nls iter residual rel tested scipy reason unable compile master branch build src linux scipy optimize cobyla cobylamodule error npy farray undeclared first use function'}, {'indice': np.int64(1368), 'score': np.float32(0.69406784), 'text': 'Title: sync rebase. Body: suggest sync rebase option sync times find manually run two commands simply sync uses regular pull want edit git configuration always rebase either think makes sense sync rebase option since already pull rebase sync uses pull'}, {'indice': np.int64(1226), 'score': np.float32(0.6936485), 'text': 'Title: login css. Body: sur page login apr avoir rentrer faux identifiant mdp phrase invalid credentials affiche gauche'}, {'indice': np.int64(1707), 'score': np.float32(0.69246674), 'text': 'Title: dns rdns. Body: create dns record domain create record try set rdns property address get match found reverse dns must matching forward entry think may dns records replicated yet clear long wait replication maybe check internal dns database first validating rdns maybe dns record created existing server rdns created automatically'}, {'indice': np.int64(1659), 'score': np.float32(0.69215304), 'text': 'Title: casos uso. Body: casos uso foram alterados tanto diagrama foram alterados especifica pois apresentavam pos condi'}, {'indice': np.int64(582), 'score': np.float32(0.6908773), 'text': 'Title: spell npc. Body: forge camp maggedon invasion point annihilator hellfire peninsula sisters grief warlocks use spell enslave demon create macro repeating cast lash pain spell deal damage fast user press button killing almost every mob instantly'}, {'indice': np.int64(782), 'score': np.float32(0.69030344), 'text': 'Title: mute plugs. Body: plugs notably output plugs trigger external events like http queries need update internal plug info constant rate rather query internal channels requested info therefore plugs could initialize need executed every time'}, {'indice': np.int64(1717), 'score': np.float32(0.69000787), 'text': 'Title: dts files. Body: using nvidia shield denon avr receiver enabled audio settings audio passthrough described playing dts file receiver switches dts get sound playback time weird second playback takes seconds tried changing audio settings nothing seems resolve issue thanks advance help'}, {'indice': np.int64(1023), 'score': np.float32(0.68988323), 'text': 'Title: ecl lib geo. Body: geo functionality used firmware well ecl wondering worth effort combine make separated lib least use one ecl whatever closing diff ecl geo firmware geo prefer create separated lib used projects well'}, {'indice': np.int64(632), 'score': np.float32(0.68965006), 'text': 'Title: add npm. Body: hey still using guss rem trying reduce amount dependency management find using bower use plugin almost everything else either moved npm also registered npm would willing add guss rem npm paul'}]\n"
     ]
    }
   ],
   "source": [
    "#definir o limiar, fazer um loop retornando os melhores índices\n",
    "limiar = 0.30\n",
    "lista_final = []\n",
    "\n",
    "for i in range(len(top_indices)):\n",
    "    if scores[top_indices[i]] > limiar:\n",
    "        lista_final.append({\"indice\" : top_indices[i] ,\"score\" :scores[top_indices[i]], \"text\" : df.iloc[top_indices[i]][\"final_text\"]})\n",
    "\n",
    "print(lista_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd2c9c",
   "metadata": {},
   "source": [
    "**Construção do contexto**\n",
    "\n",
    "- Utilizar dos dados retornados a partir do limiar e construir os textos mais similares para servir de entrada para LLM\n",
    "- estou retornando em texto todos os documentos analisados que passaram pelo limiar, poderia restringir a quantidade caso o número de tokens a ser utilizado na LLM seja limitado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4df7eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Contexto 1 |Similaridade: 0.713]\n",
      "Title: add readme. Body: holofart release soon\n",
      "\n",
      "[Contexto 2 |Similaridade: 0.708]\n",
      "Title: css html. Body: peab tama sti telefonist fikseeritud suurused peaksid asenduma ekraani suhtes lemine bar peab olema loetud hest php lehest konsuulteeri kasv lauriga lemisel baril peab olema ike koht kuhu tuleb avatar parem serv kuhu peale klikkides tuleb men kus vajalikud kaskutaja asjad veel kord lisapostitus profiil seaded logi lja eelmisega seoes vaja luua uus vaade mis kasutab sama css mis kujutaks kasutaja profiili vaade mis pole saadaval kui pole sisse logitud seal siis lihtsalt sul vaja luua keskse koha kuhu heb kasutaja avatar siis koha selle kuhu hevad kasutaja andmed avatarist leval iks olla kasutajanimi allpool email millal registreerus hetkel rohkem midagi pole vaja siis veel allpool selles iks olla valmiskoht kasutaja postituste nimekirja laadimiseks sinu asi siin hetkel vaid kujundust luua mingit loogikat taha pole vaja panna veel postituste lehel peal olema tekst pildi mber igal pool mitte vaid paremal postituste lehel postituste rval peab olema reitingu kast funktsionaalsust lge pole vaja panna esitamist htaeg dal hiljemalt\n",
      "\n",
      "[Contexto 3 |Similaridade: 0.706]\n",
      "Title: add gui. Body: would like suggest menu opens command bsadmingui nickname menu teleport player island lock unlock island lot things player island\n",
      "\n",
      "[Contexto 4 |Similaridade: 0.703]\n",
      "Title: dkim ses. Body: terraform version terraform expected behavior look like aws provider allows generate dkim settings domain references\n",
      "\n",
      "[Contexto 5 |Similaridade: 0.701]\n",
      "Title: module vydiarnfileuploader requires main queue setup since overrides init implement requiresmainqueuesetup future release react native default initializing native modules background thread unless explicitly opted. Body: module vydiarnfileuploader requires main queue setup since overrides init implement requiresmainqueuesetup future release react native default initializing native modules background thread unless explicitly opted\n",
      "\n",
      "[Contexto 6 |Similaridade: 0.700]\n",
      "Title: realdonaldtrump obamacare premiums going predicting two years obamacare owned democrats disaster worry even though dems want obstruct repeal amp replace right tax cuts. Body: realdonaldtrump obamacare premiums going predicting two years obamacare owned democrats disaster worry even though dems want obstruct repeal amp replace right tax cuts via twitter november\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lista_final = sorted(\n",
    "    lista_final,\n",
    "    key=lambda x: x[\"score\"],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "contexto = \"\"\n",
    "limite = 6\n",
    "\n",
    "if len(lista_final) <= limite:\n",
    "    for i in range(len(lista_final)):\n",
    "        contexto += (\n",
    "            f\"[Contexto {i+1} |\"\n",
    "            f\"Similaridade: {lista_final[i]['score']:.03f}]\\n\"\n",
    "            f\"{lista_final[i]['text']}\\n\\n\" \n",
    "        )\n",
    "else:\n",
    "    for i in range(limite):\n",
    "        contexto += (\n",
    "            f\"[Contexto {i+1} |\"\n",
    "            f\"Similaridade: {lista_final[i]['score']:.03f}]\\n\"\n",
    "            f\"{lista_final[i]['text']}\\n\\n\" \n",
    "        )\n",
    "\n",
    "print(contexto) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
