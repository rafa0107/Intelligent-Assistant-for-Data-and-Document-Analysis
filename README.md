# Intelligent Assistant for Data and Document Analysis

## ğŸ“Œ VisÃ£o Geral

Este projeto implementa um **Assistente Inteligente baseado em RAG (Retrieval-Augmented Generation)** para anÃ¡lise de dados e documentos. Ele combina **busca semÃ¢ntica**, **embeddings** e **LLMs (Google Gemini)** para responder perguntas com base em um conjunto de documentos previamente processados.

A aplicaÃ§Ã£o foi desenvolvida em **Python**, utiliza **Streamlit** como interface web e estÃ¡ preparada para **deploy em ambientes cloud (Streamlit Community Cloud)**.

---

## ğŸ§  Arquitetura Geral

O sistema segue uma arquitetura modular, separando claramente:

- **UI / AplicaÃ§Ã£o** (Streamlit)
- **ServiÃ§o de RAG** (orquestraÃ§Ã£o)
- **Pipeline de RecuperaÃ§Ã£o** (retriever + validaÃ§Ã£o)
- **Camada LLM** (Gemini)
- **Dados e Embeddings**

Fluxo resumido:

```
UsuÃ¡rio â†’ Streamlit UI â†’ RAGService
        â†’ Retriever (embeddings)
        â†’ ValidaÃ§Ã£o de contexto
        â†’ Prompt Builder
        â†’ Gemini LLM
        â†’ Resposta
```

---

## ğŸ“‚ Estrutura do Projeto

```
Intelligent-Assistant-for-Data-and-Document-Analysis/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ app.py                 # Interface Streamlit
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ application/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ rag_service.py      # ServiÃ§o principal de RAG
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pipeline.py         # OrquestraÃ§Ã£o do RAG
â”‚   â”‚   â”œâ”€â”€ retriever.py        # Busca semÃ¢ntica
â”‚   â”‚   â”œâ”€â”€ context_builder.py  # ConstruÃ§Ã£o de contexto
â”‚   â”‚   â””â”€â”€ validator.py        # ValidaÃ§Ã£o de contexto
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ gemini_client.py    # IntegraÃ§Ã£o com Google Gemini
â”‚   â”‚
â”‚   â””â”€â”€ prompts/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ rag_prompts.py      # Prompts e classificaÃ§Ã£o de perguntas
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ embeddings.npy     # Embeddings prÃ©-processados
â”‚       â””â”€â”€ issue_processed.csv
â”‚
â”œâ”€â”€ notebooks/                 # ExploraÃ§Ã£o e experimentos
â”œâ”€â”€ requirements.txt           # DependÃªncias do projeto
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## ğŸš€ Tecnologias Utilizadas

### Backend / IA
- **Python 3.11**
- **Sentence-Transformers** (MiniLM multilingual)
- **NumPy / Pandas**
- **Scikit-learn**
- **Google Gemini (google-genai)**

### Frontend
- **Streamlit**

### Infra / Deploy
- **Streamlit Community Cloud**
- **GitHub**

---

## ğŸ” RAG (Retrieval-Augmented Generation)

O RAG funciona em mÃºltiplas etapas:

1. **Embedding do Dataset** (offline)
2. **Busca SemÃ¢ntica** com similaridade vetorial
3. **SeleÃ§Ã£o dos documentos mais relevantes** (`top_k`)
4. **ValidaÃ§Ã£o de contexto** (evita alucinaÃ§Ãµes)
5. **ConstruÃ§Ã£o dinÃ¢mica do prompt**
6. **GeraÃ§Ã£o da resposta via LLM**

### ParÃ¢metros principais

```python
RAGService(
    top_k=30,
    similarity_threshold=0.30,
    max_context_chars=800,
    max_documents=6
)
```

---

## ğŸ§© ServiÃ§o Principal (`RAGService`)

O `RAGService` Ã© responsÃ¡vel por:

- Receber a pergunta do usuÃ¡rio
- Executar o pipeline de recuperaÃ§Ã£o
- Garantir que hÃ¡ contexto suficiente
- Delegar a geraÃ§Ã£o de resposta ao LLM

Ele atua como **fachada** entre a UI e o pipeline interno.

---

## ğŸ¤– IntegraÃ§Ã£o com Google Gemini

A integraÃ§Ã£o Ã© feita via `google-genai`.

- A **API Key nÃ£o Ã© armazenada**
- O usuÃ¡rio fornece a chave via interface Streamlit
- A configuraÃ§Ã£o ocorre **uma Ãºnica vez por sessÃ£o**

```python
configure_gemini(api_key)
```

---

## ğŸ–¥ Interface (Streamlit)

Funcionalidades da UI:

- Input seguro da API Key
- Chat interativo
- HistÃ³rico de mensagens por sessÃ£o
- Feedback visual (spinner de processamento)

---

## ğŸ“Š Dados e Embeddings

Os dados sÃ£o:

- **Baixados e processados previamente** (offline)
- Armazenados em `data/processed/`
- Carregados em tempo de execuÃ§Ã£o no deploy

âš ï¸ O processamento pesado **nÃ£o ocorre no deploy**, garantindo:
- InicializaÃ§Ã£o rÃ¡pida
- Menor custo computacional

---

## ğŸ“¦ InstalaÃ§Ã£o Local

### 1ï¸âƒ£ Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/intelligent-assistant-for-data-and-document-analysis.git
cd intelligent-assistant-for-data-and-document-analysis
```

### 2ï¸âƒ£ Crie um ambiente virtual

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

### 3ï¸âƒ£ Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Execute a aplicaÃ§Ã£o

```bash
streamlit run app/app.py
```

---

## â˜ï¸ Deploy (Streamlit Cloud)

Requisitos:

- `requirements.txt` configurado
- Python 3.11
- Caminho principal: `app/app.py`

Nenhuma variÃ¡vel secreta Ã© obrigatÃ³ria, pois a API Key Ã© fornecida via UI.

---

## ğŸ” SeguranÃ§a

- API Key do Gemini **nÃ£o Ã© persistida**
- Uso restrito Ã  sessÃ£o atual
- Sem armazenamento de dados do usuÃ¡rio

---

## ğŸ“ˆ PossÃ­veis Melhorias Futuras

- PersistÃªncia de sessÃµes
- Suporte a mÃºltiplos datasets
- Upload dinÃ¢mico de documentos
- Cache vetorial em banco (FAISS / Chroma)
- AvaliaÃ§Ã£o automÃ¡tica de respostas

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a licenÃ§a **MIT**.

---

## ğŸ‘¤ Autor

Desenvolvido por **Rafael**  
Projeto com foco em **IA aplicada, RAG e engenharia de software**.

---

Se vocÃª chegou atÃ© aqui: â­ considere dar uma estrela no repositÃ³rio!

