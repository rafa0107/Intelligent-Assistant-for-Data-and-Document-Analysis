{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13bdecc",
   "metadata": {},
   "source": [
    "**# Importanto o Dataset e verificando o conteúdo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7709c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rafae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           issue_url  \\\n",
      "0  \"https://github.com/zhangyuanwei/node-images/i...   \n",
      "1     \"https://github.com/Microsoft/pxt/issues/2543\"   \n",
      "2  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
      "3  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
      "4  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
      "\n",
      "                                         issue_title  \\\n",
      "0  can't load the addon. issue to: https://github...   \n",
      "1  hcl accessibility a11yblocking a11ymas mas4.2....   \n",
      "2  issue 1265: issue 1264: issue 1261: issue 1260...   \n",
      "3  issue 1266: issue 1263: issue 1262: issue 1259...   \n",
      "4  issue 1288: issue 1285: issue 1284: issue 1281...   \n",
      "\n",
      "                                                body  \n",
      "0  can't load the addon. issue to: https://github...  \n",
      "1  user experience: user who depends on screen re...  \n",
      "2  ┆attachments: <a href= https:& x2f;& x2f;githu...  \n",
      "3  gitlo = github x trello\\n---\\nthis board is no...  \n",
      "4  ┆attachments: <a href= https:& x2f;& x2f;githu...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\Desktop\\Portifolio\\AI_ASSISTANT_GITHUB\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rafae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords') #carrego stopwrds para filtragem NLP\n",
    "\n",
    "# Adiciona o caminho da pasta onde o arquivo 'dataset.py' está localizado\n",
    "# Isso pula a necessidade de mencionar a pasta com hífen no import\n",
    "caminho_raw = os.path.abspath(os.path.join('..', 'data', 'raw'))\n",
    "if caminho_raw not in sys.path:\n",
    "    sys.path.append(caminho_raw)\n",
    "\n",
    "from dataset import carregar_dados\n",
    "\n",
    "df = carregar_dados()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010a67a",
   "metadata": {},
   "source": [
    "**Processamento e limpeza dos dados**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "427d4c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média de palavras em url: 1.0, em title: 5.459, em body: 28.4455\n",
      "Resultados para 'issue_url':\n",
      "- Valores Nulos (NaN): 0\n",
      "- Textos Vazios/Espaços: 0\n",
      "Resultados para 'clean_title':\n",
      "- Valores Nulos (NaN): 0\n",
      "- Textos Vazios/Espaços: 99\n",
      "Resultados para 'clean_body':\n",
      "- Valores Nulos (NaN): 0\n",
      "- Textos Vazios/Espaços: 11\n",
      "Palavras mais frequentes em titles: [('issu', 352), ('add', 151), ('bug', 137), ('found', 79), ('error', 49), ('test', 43), ('use', 39), ('api', 39), ('help', 34), ('fix', 34), ('new', 33), ('need', 26), ('log', 24), ('run', 23), ('list', 22), ('get', 20), ('set', 19), ('line', 17), ('typo', 17), ('task', 16)]\n",
      "Palavras mais frequentes em body: [('close', 1244), ('add', 1102), ('issues', 927), ('columns', 714), ('list', 585), ('comment', 558), ('column', 542), ('trello', 529), ('update', 396), ('default', 387), ('settings', 378), ('via', 376), ('sync', 373), ('move', 369), ('custom', 367), ('board', 358), ('card', 357), ('attachments', 355), ('cards', 353), ('matisiekpl', 352)]\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..', 'data', 'raw')))\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'data', 'processed')))\n",
    "\n",
    "\n",
    "from dataset import verifica_vazios, verifica_frequentes\n",
    "from data_processing import clean_text\n",
    "\n",
    "df[\"clean_title\"] = df[\"issue_title\"].apply(clean_text)\n",
    "df[\"clean_body\"] = df[\"body\"].apply(clean_text)\n",
    "\n",
    "\n",
    "media_palavras_url = df[\"issue_url\"].str.split().str.len().mean()\n",
    "media_palavras_title = df[\"clean_title\"].str.split().str.len().mean()\n",
    "media_palavras_body = df[\"clean_body\"].str.split().str.len().mean()\n",
    "\n",
    "print(f\"Média de palavras em url: {media_palavras_url}, em title: {media_palavras_title}, em body: {media_palavras_body}\")\n",
    "\n",
    "url_vazio = verifica_vazios(df,\"issue_url\")\n",
    "titles_vazio = verifica_vazios(df,\"clean_title\")\n",
    "body_vazio = verifica_vazios(df,\"clean_body\")\n",
    "\n",
    "palavras_frequentes_titles = verifica_frequentes(df,\"clean_title\", 20)\n",
    "print(f\"Palavras mais frequentes em titles: {palavras_frequentes_titles}\")\n",
    "palavras_frequentes_body = verifica_frequentes(df,\"clean_body\", 20)\n",
    "print(f\"Palavras mais frequentes em body: {palavras_frequentes_body}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68051a23",
   "metadata": {},
   "source": [
    "\n",
    "   **Análise descritiva dos dados processados**\n",
    "\n",
    "- Média de palavras para entender quantos tokens irão ser processados pela LLM\n",
    "    - Quantidade de células vazias em todas as colunas\n",
    "        - não teve resultado de células vazias, todas preenchidas\n",
    "    - Títulos - tamanhos médio de 5,4 palavras\n",
    "    - Body - Aproximadamente 28 palavras\n",
    "- Ideal para:\n",
    "    - Embeddings\n",
    "    - Chunking Leve\n",
    "    - RAG Eficiente(baixo custo e boa semântica)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d86188",
   "metadata": {},
   "source": [
    "**Criação de Texto final**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4683ea7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 850.83it/s, Materializing param=pooler.dense.weight]                               \n",
      "BertModel LOAD REPORT from: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>load addon issue error lib libc version glibc ...</td>\n",
       "      <td>load addon issue error lib libc version glibc ...</td>\n",
       "      <td>Title: load addon issue error lib libc version...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hcl accessibility yblocking ymas mas hcl makec...</td>\n",
       "      <td>user experience user depends screen reader get...</td>\n",
       "      <td>Title: hcl accessibility yblocking ymas mas hc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>issue issue issue issue issue issue issue issu...</td>\n",
       "      <td>attachments github com matisiekpl czekolada is...</td>\n",
       "      <td>Title: issue issue issue issue issue issue iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>issue issue issue issue issue issue issue issu...</td>\n",
       "      <td>gitlo github trello board linked update issue ...</td>\n",
       "      <td>Title: issue issue issue issue issue issue iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>issue issue issue issue issue issue issue issu...</td>\n",
       "      <td>attachments github com matisiekpl czekolada is...</td>\n",
       "      <td>Title: issue issue issue issue issue issue iss...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title  \\\n",
       "0  load addon issue error lib libc version glibc ...   \n",
       "1  hcl accessibility yblocking ymas mas hcl makec...   \n",
       "2  issue issue issue issue issue issue issue issu...   \n",
       "3  issue issue issue issue issue issue issue issu...   \n",
       "4  issue issue issue issue issue issue issue issu...   \n",
       "\n",
       "                                          clean_body  \\\n",
       "0  load addon issue error lib libc version glibc ...   \n",
       "1  user experience user depends screen reader get...   \n",
       "2  attachments github com matisiekpl czekolada is...   \n",
       "3  gitlo github trello board linked update issue ...   \n",
       "4  attachments github com matisiekpl czekolada is...   \n",
       "\n",
       "                                          final_text  \n",
       "0  Title: load addon issue error lib libc version...  \n",
       "1  Title: hcl accessibility yblocking ymas mas hc...  \n",
       "2  Title: issue issue issue issue issue issue iss...  \n",
       "3  Title: issue issue issue issue issue issue iss...  \n",
       "4  Title: issue issue issue issue issue issue iss...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#criação de nova coluna para texto final que será direcionado ao embedding\n",
    "df[\"final_text\"] = (\n",
    "    \"Title: \" + df[\"clean_title\"] +\n",
    "    \". Body: \" + df[\"clean_body\"]\n",
    ")\n",
    "\n",
    "#carregando o modelo que será usado, modelo rápido e leve para projeto OBS: Uso da CPU pois GPU esta ultrapassada para o modelo\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\", device=\"cpu\") #usando o paraphrasal para poder perguntar em portugues\n",
    "df[[\"clean_title\", \"clean_body\", \"final_text\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c24c0a4",
   "metadata": {},
   "source": [
    "**Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f18f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 63/63 [00:15<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#listando o texto final em variavel para ser codificada\n",
    "texts = df[\"final_text\"].tolist()\n",
    "\n",
    "#realização do embedding pelo modelo escolhido\n",
    "embeddings = model.encode( \n",
    "    texts,\n",
    "    show_progress_bar= True\n",
    ")\n",
    "\n",
    "#criação do array em np \n",
    "embeddings = np.array(embeddings)\n",
    "print(embeddings.shape)\n",
    "\n",
    "#persistindo os dados em formato npy e csv para nao necessitar de conversao novamente\n",
    "np.save(\"embeddings.npy\",embeddings)\n",
    "df.to_csv(\"issue_processed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f82ff1",
   "metadata": {},
   "source": [
    "**Busca Semântica**\n",
    "\n",
    "- Primeiramente utilizarei busca ingênua para este caso, mais rápido e ideal para projetos pequenos.\n",
    "    - será utilizado semelhança de cossenos, variância de -1 a 1, sendo 1 o mais próximo.\n",
    "    - comparação de vetores do embedding, modelo utilizado de dimensão 384\n",
    "- Após implementado e projeto funconando, irei dar updgrade para utilizar índice vetorial\n",
    "- Devido a arquitetura proposta relacionado aos tipos de perguntas para o Chatbot, será implementado:\n",
    "    - Busca semântica\n",
    "    - Top k\n",
    "    - Limiar de similiaridade\n",
    "    Dessa forma será possível a resposta de perguntas analtícas e explicativas, não somente localizadoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ddcf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #ler diretamente esta célula sem precisar converter novamente os arquivos no embedding\n",
    "import numpy as np\n",
    "\n",
    "embeddings = np.load(\"embeddings.npy\")\n",
    "df = pd.read_csv(\"issue_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142573a2",
   "metadata": {},
   "source": [
    "**Exemplo de pergunta e formato para query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58b58c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n",
      "[ 914 1965  889 ...  885 1725  571]\n",
      "[ 571 1725  885 1729  976  736  844 1736 1637  549  539  596  494  959\n",
      " 1082  538  583 1635 1513 1872 1342 1625 1659  522  462  698  419 1476\n",
      "  356 1630]\n"
     ]
    }
   ],
   "source": [
    "from semantic_search import encode_query, cosine_similiarity_func\n",
    "\n",
    "pergunta = \"Quais são os erros mais recorrentes no documento?\"\n",
    "query = encode_query(model, [pergunta])\n",
    "#print(query.shape)\n",
    "\n",
    "scores = cosine_similiarity_func(query,embeddings)\n",
    "scores = scores.flatten()\n",
    "scores_ordenados = np.argsort(scores)\n",
    "print(scores.shape)\n",
    "print(scores_ordenados)\n",
    "\n",
    "#fazendo busca top_k, depois refatorar montando em funcoes definidas\n",
    "# Atualizar o Readme e usar o topk como parametro para busca ao refatorar “Utilizamos top-k dinâmico para balancear cobertura semântica e precisão.”\n",
    "top_k = 30\n",
    "top_indices = scores_ordenados[-top_k:][::-1] #quero buscar os ultimos 20 valores e ordena-los em sequência maior para menor, pois np.arg retorna ordem crescente\n",
    "print(top_indices)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2040c41",
   "metadata": {},
   "source": [
    "**Implementando Limiar de similaridade**\n",
    "\n",
    " - Utilizei um limiar de similaridade cosseno ajustado empiricamente para garantir que apenas documentos semanticamente relevantes sejam utilizados como contexto para a LLM, reduzindo ruído e alucinação.\n",
    " - A princípio foi definido padrão = 0.30, após verifiquei de forma empirica os melhores valores para retornar respostas completas sem interferências de dados fora do padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "808f1706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'indice': np.int64(571), 'score': np.float32(0.42988878), 'text': 'Title: . Body: according demo code returns standard errors according code column naming seems return standard deviations meantime assuming model returns standard deviations using boot boot empirical standard errors slow already including less unwieldy method computing kind standard errors report paper would happy clarification also information getting code work kept running error error abs max beta beta tol maxit missing value true false needed ultimately got around explicitly setting intercept input formula model matrix computed model matrix zero'}, {'indice': np.int64(1725), 'score': np.float32(0.41551167), 'text': 'Title: err code. Body: believe past issue regarding error message get run test dataset two output files params txt spades log help would greatly appreciated thanks marybel'}, {'indice': np.int64(885), 'score': np.float32(0.41383582), 'text': 'Title: typo. Body: basic security testing ios word repeated twice blatant tampering course invalidates code signature'}, {'indice': np.int64(1729), 'score': np.float32(0.41157728), 'text': 'Title: error log. Body: sure pointing larger problem individual file log incorrect info identified input file original file name two different files see attached example going fernando fscan scx log'}, {'indice': np.int64(976), 'score': np.float32(0.4087271), 'text': 'Title: bug test. Body: state failed order happend must find fix'}, {'indice': np.int64(736), 'score': np.float32(0.40729272), 'text': 'Title: null. Body: bulk insert seemed successful according log however checked database data inserted might cause book import books'}, {'indice': np.int64(844), 'score': np.float32(0.39578885), 'text': 'Title: tbody. Body: please put index page requires table output help people understand errors'}, {'indice': np.int64(1736), 'score': np.float32(0.3888807), 'text': 'Title: erros lib. Body: pequeno erro nos testes falta dulo mock requirements existe ponto mais par metro importa pagarme test linha caso algu mais iniciante tente utilizar modelo ter dificuldades para come implementar'}, {'indice': np.int64(1637), 'score': np.float32(0.38358516), 'text': 'Title: bug report. Body: wykresach nak adaj dane przy kolejnych pomiarach'}, {'indice': np.int64(549), 'score': np.float32(0.38208055), 'text': 'Title: line. Body: brf number crashes impacted devices lot information crash crashlytics com'}, {'indice': np.int64(539), 'score': np.float32(0.381408), 'text': 'Title: insert. Body: organization name individual dcma organization type document reference include section paragraph number executive summary comment include rationale comment insert suggested change read requirement organization type federal industry academia self'}, {'indice': np.int64(596), 'score': np.float32(0.37785763), 'text': 'Title: line. Body: number crashes impacted devices lot information crash crashlytics com'}, {'indice': np.int64(494), 'score': np.float32(0.37763152), 'text': 'Title: . Body: found two problems used lua function test print print end test lua function test local error compilechunk print end test thanks help'}, {'indice': np.int64(959), 'score': np.float32(0.37656683), 'text': 'Title: line. Body: com tencent qqlive ona utils number crashes impacted devices lot information crash crashlytics com'}, {'indice': np.int64(1082), 'score': np.float32(0.37634858), 'text': 'Title: found bug. Body: need report bug'}, {'indice': np.int64(538), 'score': np.float32(0.37621439), 'text': 'Title: insert. Body: organization name individual dcma organization type document reference include section paragraph number comment include rationale comment insert suggested change read owned patient organization type federal industry academia self'}, {'indice': np.int64(583), 'score': np.float32(0.37239715), 'text': 'Title: tests. Body: est dommage que fichier soit vide surtout quand dans ton historique commits des trucs genre fix machin truc framework pour les tests est super bien foutu permet vraiment faire des choses assez bal zes alors sans aller jusqu tout tester encore que aide vraiment mettre moins mettre les bugs que rencontres'}, {'indice': np.int64(1635), 'score': np.float32(0.3695712), 'text': 'Title: bug simpl. Body: note issue created automatically bugzilla github tool original bug date mattam reported version unspecified herbelin last updated mattam following example simpl creates ill typed term inductive univ set ubool unat uarrow univ univ fixpoint interp univ type match ubool bool unat nat uarrow interp interp end eval compute interp definition foo comp univ interp interp variable univ variable interp interp goal foo comp uarrow intros set printing simpl reflexivity qed herbelin fixed trunk branch revision fixed means simpl apply case unfolding constant reversible hugo'}, {'indice': np.int64(1513), 'score': np.float32(0.3634266), 'text': 'Title: test issue. Body: jirwin created issue slack'}, {'indice': np.int64(1872), 'score': np.float32(0.36312804), 'text': 'Title: apear. Body: internal server error server encountered internal error unable complete request either server overloaded error application browser error apscheduler executors default job main trigger interval next run cest raised exception traceback recent call last file usr local lib python dist packages apscheduler executors base line run job retval job func job args job kwargs file schedule proxyrefreshschedule line main refresh file manager proxymanager line refresh proxy getattr getfreeproxy proxygetter strip file proxygetter getfreeproxy line freeproxysecond html gethtmltext url headers header file util utilfunction line gethtmltext return response status code unboundlocalerror local variable response referenced assignment terminal solve'}, {'indice': np.int64(1342), 'score': np.float32(0.36256176), 'text': 'Title: save pdf. Body: generate excel file lock passphrase publish pdf excel routine invalidate excel display publish directly pdf'}, {'indice': np.int64(1625), 'score': np.float32(0.36157635), 'text': 'Title: box events. Body: description update events docs reflect known limitations expectations best practices'}, {'indice': np.int64(1659), 'score': np.float32(0.36020154), 'text': 'Title: casos uso. Body: casos uso foram alterados tanto diagrama foram alterados especifica pois apresentavam pos condi'}, {'indice': np.int64(522), 'score': np.float32(0.35997775), 'text': 'Title: ent dec. Body: entero decimal entero los ejemplos dice ent dec dec talvez error asi'}, {'indice': np.int64(462), 'score': np.float32(0.35843253), 'text': 'Title: issues. Body: new issue test'}, {'indice': np.int64(698), 'score': np.float32(0.3577703), 'text': 'Title: fix. Body: still lots problems needs thorough testing launch'}, {'indice': np.int64(419), 'score': np.float32(0.35414052), 'text': 'Title: issue. Body: commits one line'}, {'indice': np.int64(1476), 'score': np.float32(0.3534499), 'text': 'Title: crash. Body: updating ancient trees kore sample experience following crash crash client txt'}, {'indice': np.int64(356), 'score': np.float32(0.35279757), 'text': 'Title: invalid. Body: judge eee'}, {'indice': np.int64(1630), 'score': np.float32(0.35272202), 'text': 'Title: bug annexe. Body: pour info sur prod pprd quand lance export annexe sur cee tombe sur une erreur est probl que issue blocage export hceres contrat cours onglet activit doctorat manquante'}]\n"
     ]
    }
   ],
   "source": [
    "#definir o limiar, fazer um loop retornando os melhores índices\n",
    "limiar = 0.30\n",
    "lista_final = []\n",
    "\n",
    "for i in range(len(top_indices)):\n",
    "    if scores[top_indices[i]] > limiar:\n",
    "        lista_final.append({\"indice\" : top_indices[i] ,\"score\" :scores[top_indices[i]], \"text\" : df.iloc[top_indices[i]][\"final_text\"]})\n",
    "\n",
    "print(lista_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd2c9c",
   "metadata": {},
   "source": [
    "**Construção do contexto**\n",
    "\n",
    "- Utilizar dos dados retornados a partir do limiar e construir os textos mais similares para servir de entrada para LLM\n",
    "- estou retornando em texto todos os documentos analisados que passaram pelo limiar, poderia restringir a quantidade caso o número de tokens a ser utilizado na LLM seja limitado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4df7eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Contexto 1 | Similaridade: 0.430]\n",
      "Title: . Body: according demo code returns standard errors according code column naming seems return standard deviations meantime assuming model returns standard deviations using boot boot empirical standard errors slow already including less unwieldy method computing kind standard errors report paper would happy clarification also information getting code work kept running error error abs max beta beta tol maxit missing value true false needed ultimately got around explicitly setting intercept input formula model matrix computed model matrix zero\n",
      "\n",
      "[Contexto 2 | Similaridade: 0.416]\n",
      "Title: err code. Body: believe past issue regarding error message get run test dataset two output files params txt spades log help would greatly appreciated thanks marybel\n",
      "\n",
      "[Contexto 3 | Similaridade: 0.414]\n",
      "Title: typo. Body: basic security testing ios word repeated twice blatant tampering course invalidates code signature\n",
      "\n",
      "[Contexto 4 | Similaridade: 0.412]\n",
      "Title: error log. Body: sure pointing larger problem individual file log incorrect info identified input file original file name two different files see attached example going fernando fscan scx log\n",
      "\n",
      "[Contexto 5 | Similaridade: 0.409]\n",
      "Title: bug test. Body: state failed order happend must find fix\n",
      "\n",
      "[Contexto 6 | Similaridade: 0.407]\n",
      "Title: null. Body: bulk insert seemed successful according log however checked database data inserted might cause book import books\n",
      "\n",
      "[Contexto 7 | Similaridade: 0.396]\n",
      "Title: tbody. Body: please put index page requires table output help people understand errors\n",
      "\n",
      "[Contexto 8 | Similaridade: 0.389]\n",
      "Title: erros lib. Body: pequeno erro nos testes falta dulo mock requirements existe ponto mais par metro importa pagarme test linha caso algu mais iniciante tente utilizar modelo ter dificuldades para come implementar\n",
      "\n",
      "[Contexto 9 | Similaridade: 0.384]\n",
      "Title: bug report. Body: wykresach nak adaj dane przy kolejnych pomiarach\n",
      "\n",
      "[Contexto 10 | Similaridade: 0.382]\n",
      "Title: line. Body: brf number crashes impacted devices lot information crash crashlytics com\n",
      "\n",
      "[Contexto 11 | Similaridade: 0.381]\n",
      "Title: insert. Body: organization name individual dcma organization type document reference include section paragraph number executive summary comment include rationale comment insert suggested change read requirement organization type federal industry academia self\n",
      "\n",
      "[Contexto 12 | Similaridade: 0.378]\n",
      "Title: line. Body: number crashes impacted devices lot information crash crashlytics com\n",
      "\n",
      "[Contexto 13 | Similaridade: 0.378]\n",
      "Title: . Body: found two problems used lua function test print print end test lua function test local error compilechunk print end test thanks help\n",
      "\n",
      "[Contexto 14 | Similaridade: 0.377]\n",
      "Title: line. Body: com tencent qqlive ona utils number crashes impacted devices lot information crash crashlytics com\n",
      "\n",
      "[Contexto 15 | Similaridade: 0.376]\n",
      "Title: found bug. Body: need report bug\n",
      "\n",
      "[Contexto 16 | Similaridade: 0.376]\n",
      "Title: insert. Body: organization name individual dcma organization type document reference include section paragraph number comment include rationale comment insert suggested change read owned patient organization type federal industry academia self\n",
      "\n",
      "[Contexto 17 | Similaridade: 0.372]\n",
      "Title: tests. Body: est dommage que fichier soit vide surtout quand dans ton historique commits des trucs genre fix machin truc framework pour les tests est super bien foutu permet vraiment faire des choses assez bal zes alors sans aller jusqu tout tester encore que aide vraiment mettre moins mettre les bugs que rencontres\n",
      "\n",
      "[Contexto 18 | Similaridade: 0.370]\n",
      "Title: bug simpl. Body: note issue created automatically bugzilla github tool original bug date mattam reported version unspecified herbelin last updated mattam following example simpl creates ill typed term inductive univ set ubool unat uarrow univ univ fixpoint interp univ type match ubool bool unat nat uarrow interp interp end eval compute interp definition foo comp univ interp interp variable univ variable interp interp goal foo comp uarrow intros set printing simpl reflexivity qed herbelin fixed trunk branch revision fixed means simpl apply case unfolding constant reversible hugo\n",
      "\n",
      "[Contexto 19 | Similaridade: 0.363]\n",
      "Title: test issue. Body: jirwin created issue slack\n",
      "\n",
      "[Contexto 20 | Similaridade: 0.363]\n",
      "Title: apear. Body: internal server error server encountered internal error unable complete request either server overloaded error application browser error apscheduler executors default job main trigger interval next run cest raised exception traceback recent call last file usr local lib python dist packages apscheduler executors base line run job retval job func job args job kwargs file schedule proxyrefreshschedule line main refresh file manager proxymanager line refresh proxy getattr getfreeproxy proxygetter strip file proxygetter getfreeproxy line freeproxysecond html gethtmltext url headers header file util utilfunction line gethtmltext return response status code unboundlocalerror local variable response referenced assignment terminal solve\n",
      "\n",
      "[Contexto 21 | Similaridade: 0.363]\n",
      "Title: save pdf. Body: generate excel file lock passphrase publish pdf excel routine invalidate excel display publish directly pdf\n",
      "\n",
      "[Contexto 22 | Similaridade: 0.362]\n",
      "Title: box events. Body: description update events docs reflect known limitations expectations best practices\n",
      "\n",
      "[Contexto 23 | Similaridade: 0.360]\n",
      "Title: casos uso. Body: casos uso foram alterados tanto diagrama foram alterados especifica pois apresentavam pos condi\n",
      "\n",
      "[Contexto 24 | Similaridade: 0.360]\n",
      "Title: ent dec. Body: entero decimal entero los ejemplos dice ent dec dec talvez error asi\n",
      "\n",
      "[Contexto 25 | Similaridade: 0.358]\n",
      "Title: issues. Body: new issue test\n",
      "\n",
      "[Contexto 26 | Similaridade: 0.358]\n",
      "Title: fix. Body: still lots problems needs thorough testing launch\n",
      "\n",
      "[Contexto 27 | Similaridade: 0.354]\n",
      "Title: issue. Body: commits one line\n",
      "\n",
      "[Contexto 28 | Similaridade: 0.353]\n",
      "Title: crash. Body: updating ancient trees kore sample experience following crash crash client txt\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_CHARS = 800  # por documento\n",
    "\n",
    "lista_final = sorted(\n",
    "    lista_final,\n",
    "    key=lambda x: x[\"score\"],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "contexto = \"\"\n",
    "limite = 28\n",
    "\n",
    "if len(lista_final) <= limite:\n",
    "    for i in range(len(lista_final)):\n",
    "        text_limited = lista_final[i][\"text\"][:MAX_CHARS]\n",
    "\n",
    "        contexto += (\n",
    "            f\"[Contexto {i+1} | \"\n",
    "            f\"Similaridade: {lista_final[i]['score']:.03f}]\\n\"\n",
    "            f\"{text_limited}\\n\\n\"\n",
    "        )\n",
    "\n",
    "else:\n",
    "    for i in range(limite):\n",
    "        text_limited = lista_final[i][\"text\"][:MAX_CHARS]\n",
    "\n",
    "        contexto += (\n",
    "            f\"[Contexto {i+1} | \"\n",
    "            f\"Similaridade: {lista_final[i]['score']:.03f}]\\n\"\n",
    "            f\"{text_limited}\\n\\n\"\n",
    "        )\n",
    "\n",
    "print(contexto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d310f",
   "metadata": {},
   "source": [
    "**Integrando LLM**\n",
    "\n",
    "- Estou usando Gemini devido a facilidade de obtenção de uma chave gratuita para estudantes\n",
    "- A LLM irá receber as informações retiradas do Dataset \n",
    "- Será utilizado engenharia de prompt para qualificar a análise da LLM\n",
    "- No projeto será implantado um scan de input para o usuário digitar sua propria chave api gemini e testar o programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3ca6980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Com base nos contextos fornecidos, os erros mais recorrentes parecem estar relacionados a:\n",
      "\n",
      "*   **Erros de execução/travamentos (crashes):** Vários títulos e corpos de texto mencionam \"crash\", \"crashes impacted devices\", \"brf number crashes\" e \"crashlytics\".\n",
      "*   **Problemas com testes e bugs:** Termos como \"bug\", \"test\", \"errors\", \"issue\", \"fix\" e \"found bug\" aparecem com frequência, indicando dificuldades em testes e a descoberta de erros.\n",
      "*   **Erros de processamento de dados/resultados:** Contextos como \"standard errors\", \"standard deviations\", \"missing value\", \"incorrect info\", \"null\" e \"data inserted\" sugerem problemas na forma como os dados são processados, calculados ou inseridos.\n",
      "*   **Erros de código ou sintaxe:** Menciona-se \"error code\", \"err code\", \"typo\", \"invalidates code signature\", \"error compilechunk\" e \"unboundlocalerror\", indicando falhas na escrita ou interpretação do código.\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..', 'src', 'prompts')))\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src', 'llm')))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from rag_prompts import build_prompts\n",
    "from gemini_client import generate_answer\n",
    "\n",
    "load_dotenv()\n",
    "chave_api = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "prompt = build_prompts(contexto, pergunta)\n",
    "resposta = generate_answer(prompt)\n",
    "\n",
    "print(resposta)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
