{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13bdecc",
   "metadata": {},
   "source": [
    "**# Importanto o Dataset e verificando o conteúdo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7709c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/rafael/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           issue_url  \\\n",
      "0  \"https://github.com/zhangyuanwei/node-images/i...   \n",
      "1     \"https://github.com/Microsoft/pxt/issues/2543\"   \n",
      "2  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
      "3  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
      "4  \"https://github.com/MatisiekPL/Czekolada/issue...   \n",
      "\n",
      "                                         issue_title  \\\n",
      "0  can't load the addon. issue to: https://github...   \n",
      "1  hcl accessibility a11yblocking a11ymas mas4.2....   \n",
      "2  issue 1265: issue 1264: issue 1261: issue 1260...   \n",
      "3  issue 1266: issue 1263: issue 1262: issue 1259...   \n",
      "4  issue 1288: issue 1285: issue 1284: issue 1281...   \n",
      "\n",
      "                                                body  \n",
      "0  can't load the addon. issue to: https://github...  \n",
      "1  user experience: user who depends on screen re...  \n",
      "2  ┆attachments: <a href= https:& x2f;& x2f;githu...  \n",
      "3  gitlo = github x trello\\n---\\nthis board is no...  \n",
      "4  ┆attachments: <a href= https:& x2f;& x2f;githu...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/Desktop/Portifolio/Intelligent-Assistant-for-Data-and-Document-Analysis/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to /home/rafael/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords') #carrego stopwrds para filtragem NLP\n",
    "\n",
    "# Adiciona o caminho da pasta onde o arquivo 'dataset.py' está localizado\n",
    "# Isso pula a necessidade de mencionar a pasta com hífen no import\n",
    "caminho_raw = os.path.abspath(os.path.join('..', 'data', 'raw'))\n",
    "if caminho_raw not in sys.path:\n",
    "    sys.path.append(caminho_raw)\n",
    "\n",
    "from dataset import carregar_dados\n",
    "\n",
    "df = carregar_dados()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010a67a",
   "metadata": {},
   "source": [
    "**Processamento e limpeza dos dados**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "427d4c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média de palavras em url: 1.0, em title: 10.9025, em body: 38.63875\n",
      "Resultados para 'issue_url':\n",
      "- Valores Nulos (NaN): 0\n",
      "- Textos Vazios/Espaços: 0\n",
      "Resultados para 'clean_title':\n",
      "- Valores Nulos (NaN): 0\n",
      "- Textos Vazios/Espaços: 69\n",
      "Resultados para 'clean_body':\n",
      "- Valores Nulos (NaN): 0\n",
      "- Textos Vazios/Espaços: 4\n",
      "Palavras mais frequentes em titles: [('issu', 352), ('add', 35), ('error', 21), ('bug', 21), ('use', 18), ('set', 12), ('test', 10), ('line', 9), ('task', 9), ('jquery', 8), ('api', 8), ('fix', 6), ('training', 6), ('network', 6), ('app', 5), ('help', 5), ('npm', 5), ('load', 4), ('button', 4), ('warning', 4)]\n",
      "Palavras mais frequentes em body: [('close', 1237), ('add', 939), ('issues', 898), ('columns', 704), ('list', 540), ('comment', 538), ('column', 531), ('trello', 528), ('update', 367), ('via', 360), ('default', 360), ('move', 358), ('settings', 357), ('custom', 355), ('attachments', 352), ('matisiekpl', 352), ('czekolada', 352), ('gitlo', 352), ('board', 352), ('sync', 352)]\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..', 'data', 'raw')))\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'data', 'processed')))\n",
    "\n",
    "\n",
    "from dataset import verifica_vazios, verifica_frequentes\n",
    "from data_processing import clean_text\n",
    "\n",
    "df[\"clean_title\"] = df[\"issue_title\"].apply(clean_text)\n",
    "df[\"clean_body\"] = df[\"body\"].apply(clean_text)\n",
    "\n",
    "\n",
    "media_palavras_url = df[\"issue_url\"].str.split().str.len().mean()\n",
    "media_palavras_title = df[\"clean_title\"].str.split().str.len().mean()\n",
    "media_palavras_body = df[\"clean_body\"].str.split().str.len().mean()\n",
    "\n",
    "print(f\"Média de palavras em url: {media_palavras_url}, em title: {media_palavras_title}, em body: {media_palavras_body}\")\n",
    "\n",
    "url_vazio = verifica_vazios(df,\"issue_url\")\n",
    "titles_vazio = verifica_vazios(df,\"clean_title\")\n",
    "body_vazio = verifica_vazios(df,\"clean_body\")\n",
    "\n",
    "palavras_frequentes_titles = verifica_frequentes(df,\"clean_title\", 20)\n",
    "print(f\"Palavras mais frequentes em titles: {palavras_frequentes_titles}\")\n",
    "palavras_frequentes_body = verifica_frequentes(df,\"clean_body\", 20)\n",
    "print(f\"Palavras mais frequentes em body: {palavras_frequentes_body}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68051a23",
   "metadata": {},
   "source": [
    "\n",
    "   **Análise descritiva dos dados processados**\n",
    "\n",
    "- Média de palavras para entender quantos tokens irão ser processados pela LLM\n",
    "    - Quantidade de células vazias em todas as colunas\n",
    "        - não teve resultado de células vazias, todas preenchidas\n",
    "    - Títulos - tamanhos médio de 5,4 palavras\n",
    "    - Body - Aproximadamente 28 palavras\n",
    "- Ideal para:\n",
    "    - Embeddings\n",
    "    - Chunking Leve\n",
    "    - RAG Eficiente(baixo custo e boa semântica)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d86188",
   "metadata": {},
   "source": [
    "**Criação de Texto final**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4683ea7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>load addon issue error lib libc version glibc ...</td>\n",
       "      <td>load addon issue error lib libc version glibc ...</td>\n",
       "      <td>Title: load addon issue error lib libc version...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hcl accessibility yblocking ymas mas hcl makec...</td>\n",
       "      <td>user experience user depends screen reader get...</td>\n",
       "      <td>Title: hcl accessibility yblocking ymas mas hc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>issue issue issue issue issue issue issue issu...</td>\n",
       "      <td>attachments github com matisiekpl czekolada is...</td>\n",
       "      <td>Title: issue issue issue issue issue issue iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>issue issue issue issue issue issue issue issu...</td>\n",
       "      <td>gitlo github trello board linked update issue ...</td>\n",
       "      <td>Title: issue issue issue issue issue issue iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>issue issue issue issue issue issue issue issu...</td>\n",
       "      <td>attachments github com matisiekpl czekolada is...</td>\n",
       "      <td>Title: issue issue issue issue issue issue iss...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_title  \\\n",
       "0  load addon issue error lib libc version glibc ...   \n",
       "1  hcl accessibility yblocking ymas mas hcl makec...   \n",
       "2  issue issue issue issue issue issue issue issu...   \n",
       "3  issue issue issue issue issue issue issue issu...   \n",
       "4  issue issue issue issue issue issue issue issu...   \n",
       "\n",
       "                                          clean_body  \\\n",
       "0  load addon issue error lib libc version glibc ...   \n",
       "1  user experience user depends screen reader get...   \n",
       "2  attachments github com matisiekpl czekolada is...   \n",
       "3  gitlo github trello board linked update issue ...   \n",
       "4  attachments github com matisiekpl czekolada is...   \n",
       "\n",
       "                                          final_text  \n",
       "0  Title: load addon issue error lib libc version...  \n",
       "1  Title: hcl accessibility yblocking ymas mas hc...  \n",
       "2  Title: issue issue issue issue issue issue iss...  \n",
       "3  Title: issue issue issue issue issue issue iss...  \n",
       "4  Title: issue issue issue issue issue issue iss...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#criação de nova coluna para texto final que será direcionado ao embedding\n",
    "df[\"final_text\"] = (\n",
    "    \"Title: \" + df[\"clean_title\"] +\n",
    "    \". Body: \" + df[\"clean_body\"]\n",
    ")\n",
    "\n",
    "#carregando o modelo que será usado, modelo rápido e leve para projeto OBS: Uso da CPU pois GPU esta ultrapassada para o modelo\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\", device=\"cpu\") #usando o paraphrasal para poder perguntar em portugues\n",
    "df[[\"clean_title\", \"clean_body\", \"final_text\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c24c0a4",
   "metadata": {},
   "source": [
    "**Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f18f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 25/25 [00:13<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#listando o texto final em variavel para ser codificada\n",
    "texts = df[\"final_text\"].tolist()\n",
    "\n",
    "#realização do embedding pelo modelo escolhido\n",
    "embeddings = model.encode( \n",
    "    texts,\n",
    "    show_progress_bar= True\n",
    ")\n",
    "\n",
    "#criação do array em np \n",
    "embeddings = np.array(embeddings)\n",
    "print(embeddings.shape)\n",
    "\n",
    "#persistindo os dados em formato npy e csv para nao necessitar de conversao novamente\n",
    "np.save(\"embeddings.npy\",embeddings)\n",
    "df.to_csv(\"issue_processed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f82ff1",
   "metadata": {},
   "source": [
    "**Busca Semântica**\n",
    "\n",
    "- Primeiramente utilizarei busca ingênua para este caso, mais rápido e ideal para projetos pequenos.\n",
    "    - será utilizado semelhança de cossenos, variância de -1 a 1, sendo 1 o mais próximo.\n",
    "    - comparação de vetores do embedding, modelo utilizado de dimensão 384\n",
    "- Após implementado e projeto funconando, irei dar updgrade para utilizar índice vetorial\n",
    "- Devido a arquitetura proposta relacionado aos tipos de perguntas para o Chatbot, será implementado:\n",
    "    - Busca semântica\n",
    "    - Top k\n",
    "    - Limiar de similiaridade\n",
    "    Dessa forma será possível a resposta de perguntas analtícas e explicativas, não somente localizadoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ddcf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #ler diretamente esta célula sem precisar converter novamente os arquivos no embedding\n",
    "import numpy as np\n",
    "\n",
    "embeddings = np.load(\"embeddings.npy\")\n",
    "df = pd.read_csv(\"issue_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142573a2",
   "metadata": {},
   "source": [
    "**Exemplo de pergunta e formato para query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b58c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n",
      "[697 496 603 745 622 499 500 564 703 665 576 534 785 640 459 789 470 482\n",
      " 546 474 537 469 478 788 402 460 518 517 710 467 625 560 498 610 452 720\n",
      " 398 621 747 731 431 704 727 793 435 357 646 420 696 392 511 570 598 716\n",
      " 529 449 779 515 520 464 626 602 664 508 709 584 512 648 481 714 561 740\n",
      " 495 632 591 623 624 590 551 365 391 516 634 773 367 397 780 422 577   1\n",
      " 404 530 531 362 566 796 668 699 477 439 501 458 463 627 631 382 361 616\n",
      " 519 456 644 413 438 712 609 690 368 521 409 542 765 600 383 642 790 574\n",
      " 387 514 707 550 376 480 629 562 505 506 630 657 388 728 746 509 430 782\n",
      " 633 615 389 523 651 381 504 484 372 354 472 702 713 679 638 726 555 502\n",
      " 799 488 457 370 647 769 652 721 676 667 685 733 628 669 674 582 533 675\n",
      " 355 573 766 619 578 794 487 620 741 777 744 694 507 586 743 541 489 661\n",
      " 408 599 604   0 407 725 594 406 605 543 447 705 639 468 756 763 760 757\n",
      " 759 758 762 761 471 559 768 798 792 485 589 593 553 379 706 532 426 371\n",
      " 395 524 423 770 579 781 437 695 358 742 737 399 547 536 641 677 444 567\n",
      " 666 476 678 527 776 680 492 385 738 575 513 483 715 607 748 479 461 466\n",
      " 772 687 683 719 455 434 635 448 544 490 491 739 400 670 595 552 722 693\n",
      " 565 689 778 708 660 374 672 692 369 486 410 558 684 373 585 681 686 688\n",
      " 405 465 732 786 787 393 643 718 473 440 735 771 662 386 617  16  22  24\n",
      "  25  15 340 339 336 335 334 333  43  42  41  37  34  33  58  56  55  50\n",
      " 331 330 328 326 325 324 322 321  69  68  67  65  64  62  79  78  76  75\n",
      "  74  73  72  71 353 312  94  91  89  88  87  85  84  83 308 305 304 302\n",
      " 301 111 109 107 104 103  98  96 122 119 117 115 114 300 298 294 293 292\n",
      " 290 289 288 125 124 123 143 142 141 140 137 136 135 134 133 287 286 285\n",
      " 156 154 151 150 148 147 145 144 284 283 282 161 280 279 278 157 158 174\n",
      " 173 267 172 170 166 164 163 271 270 179 188 184 182 177 178 176 193 237\n",
      " 192 191 190 205 204 203 199 198 265 264 263 262 261 260 259 257 254 253\n",
      " 223 220 217 214 212 209 250 249 248 246 244 241 239  28 233 231 230 227\n",
      " 224  14  10   9   8   7   3 350  32  31  29 618 556 428 568 691 682 612\n",
      " 580 525 363 729 673 401 510 783 614 493 775 592 701 711 654 540 655 563\n",
      " 528 378 436 581 611 784 606 441 417 503 764 791 613 588 364 394 767 415\n",
      " 659 734 795 587 663 658 443 526 454 671 375 412 649 411 442 717 403 475\n",
      " 700 396 329 327 186 185 183 181 180 194 201 207 200 206 202 256 258 195\n",
      " 196 197 218 222 221 219 208 255 252 251 332 266 268  81  80 189  70  77\n",
      " 171 175 352 169 319 318  95 316 167 165 323 320  66 247 216  19 242 240\n",
      " 238 236 234  49 243 245  51  35 235 232  17  27  18  26 153 152 149 146\n",
      " 277 281 275 276 162 160 274 273  82  86  90  92 306 110 159 187  93 168\n",
      " 120 121 100  99  97 118 113 116 155 112 126 127 139 138 106 108 131 132\n",
      " 102 105 101 128 291  20 129 130 349 351 337 338 343 344 341 342 346 345\n",
      " 348 347  23  21  47  13  11  12   6   5   2   4 296 295 297 299 272 315\n",
      " 303 307 314 313 311 310 317 309  63 269  39  38  36  60  40  44 215  61\n",
      "  59  57 210  48 213 211  45  46  30 225  54  53  52 229 228 226 451 418\n",
      " 366 535 608 636 557 377 572 637 601 421 723 653 384 416 424 453 569 446\n",
      " 445 645 427 360 730 548 774 597 359 797 749 414 724 380 419 425 429 650\n",
      " 545 554 433 583 390 755 753 754 750 751 752 432 450 698 522 497 462 596\n",
      " 656 549 356 494 538 539 736 571]\n",
      "[571 736 539 538 494 356 549 656 596 462 497 522 698 450 432 752 751 750\n",
      " 754 753 755 390 583 433 554 545 650 429 425 419]\n"
     ]
    }
   ],
   "source": [
    "from semantic_search import encode_query, cosine_similiarity_func\n",
    "\n",
    "pergunta = \"Quais sao os erros mais registrados no documento?\"\n",
    "query = encode_query(model, [pergunta])\n",
    "#print(query.shape)\n",
    "\n",
    "scores = cosine_similiarity_func(query,embeddings)\n",
    "scores = scores.flatten()\n",
    "scores_ordenados = np.argsort(scores)\n",
    "print(scores.shape)\n",
    "print(scores_ordenados)\n",
    "\n",
    "#fazendo busca top_k, depois refatorar montando em funcoes definidas\n",
    "# Atualizar o Readme e usar o topk como parametro para busca ao refatorar “Utilizamos top-k dinâmico para balancear cobertura semântica e precisão.”\n",
    "top_k = 30\n",
    "top_indices = scores_ordenados[-top_k:][::-1] #quero buscar os ultimos 20 valores e ordena-los em sequência maior para menor, pois np.arg retorna ordem crescente\n",
    "print(top_indices)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2040c41",
   "metadata": {},
   "source": [
    "**Implementando Limiar de similaridade**\n",
    "\n",
    " - Utilizei um limiar de similaridade cosseno ajustado empiricamente para garantir que apenas documentos semanticamente relevantes sejam utilizados como contexto para a LLM, reduzindo ruído e alucinação.\n",
    " - A princípio foi definido padrão = 0.30, após verifiquei de forma empirica os melhores valores para retornar respostas completas sem interferências de dados fora do padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "808f1706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'indice': np.int64(571), 'score': np.float32(0.4546029), 'text': 'Title: . Body: according demo code returns standard errors according code column naming seems return standard deviations meantime assuming model returns standard deviations using boot boot empirical standard errors slow already including less unwieldy method computing kind standard errors report paper would happy clarification also information getting code work kept running error error abs max beta beta tol maxit missing value true false needed ultimately got around explicitly setting intercept input formula model matrix computed model matrix zero'}, {'indice': np.int64(736), 'score': np.float32(0.42092642), 'text': 'Title: null. Body: bulk insert seemed successful according log however checked database data inserted might cause book import books'}, {'indice': np.int64(539), 'score': np.float32(0.41807178), 'text': 'Title: insert. Body: organization name individual dcma organization type document reference include section paragraph number executive summary comment include rationale comment insert suggested change read requirement organization type federal industry academia self'}, {'indice': np.int64(538), 'score': np.float32(0.409754), 'text': 'Title: insert. Body: organization name individual dcma organization type document reference include section paragraph number comment include rationale comment insert suggested change read owned patient organization type federal industry academia self'}, {'indice': np.int64(494), 'score': np.float32(0.40234083), 'text': 'Title: . Body: found two problems used lua function test print print end test lua function test local error compilechunk print end test thanks help'}, {'indice': np.int64(356), 'score': np.float32(0.3896584), 'text': 'Title: invalid. Body: judge eee'}, {'indice': np.int64(549), 'score': np.float32(0.38643724), 'text': 'Title: line. Body: brf number crashes impacted devices lot information crash crashlytics com'}, {'indice': np.int64(656), 'score': np.float32(0.3786166), 'text': 'Title: bug log. Body: mar europe berlin php fatal error uncaught error call member function query null inetpub stack trace inetpub profile user showforentity object entity inetpub profile user displaytabcontentforitem object entity inetpub commonglpi displaystandardtab object entity profile user array main thrown inetpub line mar europe berlin php fatal error uncaught zend exception parseexception unknown invalid parser rule nplurals integer plural expression inetpub stack trace inetpub zend translator plural rule fromstring nplurals integ inetpub zend translator loader gettext load inetpub inetpub zend translator translator loadmessagesfromfiles mydashboard inetpub zend translator translator loadmessages mydashboard inetpub zend translator translator gettr inetpub line'}, {'indice': np.int64(596), 'score': np.float32(0.37672454), 'text': 'Title: line. Body: number crashes impacted devices lot information crash crashlytics com'}, {'indice': np.int64(462), 'score': np.float32(0.37297538), 'text': 'Title: issues. Body: new issue test'}, {'indice': np.int64(497), 'score': np.float32(0.3666302), 'text': 'Title: add faq. Body: answer common questions countries data data gathered language deduced report error suggest feature epurpose project etc'}, {'indice': np.int64(522), 'score': np.float32(0.36563557), 'text': 'Title: ent dec. Body: entero decimal entero los ejemplos dice ent dec dec talvez error asi'}, {'indice': np.int64(698), 'score': np.float32(0.36059624), 'text': 'Title: fix. Body: still lots problems needs thorough testing launch'}, {'indice': np.int64(450), 'score': np.float32(0.35757142), 'text': 'Title: adress. Body: old needs adressed properly probably useful current state code could likely used one way another nemerald adress issue since code stale branch start'}, {'indice': np.int64(432), 'score': np.float32(0.35712382), 'text': 'Title: void. Body: actually void data structures placeholders everything passed arguments pedrohsoares wykthor btracker nicholas arqui let found'}, {'indice': np.int64(752), 'score': np.float32(0.3520047), 'text': 'Title: issue. Body: bug number'}, {'indice': np.int64(751), 'score': np.float32(0.3520047), 'text': 'Title: issue. Body: bug number'}, {'indice': np.int64(750), 'score': np.float32(0.3520047), 'text': 'Title: issue. Body: bug number'}, {'indice': np.int64(754), 'score': np.float32(0.3520047), 'text': 'Title: issue. Body: bug number'}, {'indice': np.int64(753), 'score': np.float32(0.3520047), 'text': 'Title: issue. Body: bug number'}, {'indice': np.int64(755), 'score': np.float32(0.3520047), 'text': 'Title: issue. Body: bug number'}, {'indice': np.int64(390), 'score': np.float32(0.3514721), 'text': 'Title: task. Body: ronitron complete form validations registrations form done closed'}, {'indice': np.int64(583), 'score': np.float32(0.3432262), 'text': 'Title: tests. Body: est dommage que fichier soit vide surtout quand dans ton historique commits des trucs genre fix machin truc framework pour les tests est super bien foutu permet vraiment faire des choses assez bal zes alors sans aller jusqu tout tester encore que aide vraiment mettre moins mettre les bugs que rencontres'}, {'indice': np.int64(433), 'score': np.float32(0.34031487), 'text': 'Title: req. Body: restricciones tiene para hacer esas ediciones modificaciones los datos del inventario'}, {'indice': np.int64(554), 'score': np.float32(0.33967143), 'text': 'Title: line. Body: com number crashes impacted devices lot information crash crashlytics com'}, {'indice': np.int64(545), 'score': np.float32(0.33967143), 'text': 'Title: line. Body: com number crashes impacted devices lot information crash crashlytics com'}, {'indice': np.int64(650), 'score': np.float32(0.33967143), 'text': 'Title: line. Body: com number crashes impacted devices lot information crash crashlytics com'}, {'indice': np.int64(429), 'score': np.float32(0.33880147), 'text': 'Title: issue. Body: testing issue issue'}, {'indice': np.int64(425), 'score': np.float32(0.33847442), 'text': 'Title: issue. Body: thsi teh text issue number'}, {'indice': np.int64(419), 'score': np.float32(0.33704013), 'text': 'Title: issue. Body: commits one line'}]\n"
     ]
    }
   ],
   "source": [
    "#definir o limiar, fazer um loop retornando os melhores índices\n",
    "limiar = 0.30\n",
    "lista_final = []\n",
    "\n",
    "for i in range(len(top_indices)):\n",
    "    if scores[top_indices[i]] > limiar:\n",
    "        lista_final.append({\"indice\" : top_indices[i] ,\"score\" :scores[top_indices[i]], \"text\" : df.iloc[top_indices[i]][\"final_text\"]})\n",
    "\n",
    "print(lista_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd2c9c",
   "metadata": {},
   "source": [
    "**Construção do contexto**\n",
    "\n",
    "- Utilizar dos dados retornados a partir do limiar e construir os textos mais similares para servir de entrada para LLM\n",
    "- estou retornando em texto todos os documentos analisados que passaram pelo limiar, poderia restringir a quantidade caso o número de tokens a ser utilizado na LLM seja limitado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4df7eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Contexto 1 | Similaridade: 0.455]\n",
      "Title: . Body: according demo code returns standard errors according code column naming seems return standard deviations meantime assuming model returns standard deviations using boot boot empirical standard errors slow already including less unwieldy method computing kind standard errors report paper would happy clarification also information getting code work kept running error error abs max beta beta tol maxit missing value true false needed ultimately got around explicitly setting intercept input formula model matrix computed model matrix zero\n",
      "\n",
      "[Contexto 2 | Similaridade: 0.421]\n",
      "Title: null. Body: bulk insert seemed successful according log however checked database data inserted might cause book import books\n",
      "\n",
      "[Contexto 3 | Similaridade: 0.418]\n",
      "Title: insert. Body: organization name individual dcma organization type document reference include section paragraph number executive summary comment include rationale comment insert suggested change read requirement organization type federal industry academia self\n",
      "\n",
      "[Contexto 4 | Similaridade: 0.410]\n",
      "Title: insert. Body: organization name individual dcma organization type document reference include section paragraph number comment include rationale comment insert suggested change read owned patient organization type federal industry academia self\n",
      "\n",
      "[Contexto 5 | Similaridade: 0.402]\n",
      "Title: . Body: found two problems used lua function test print print end test lua function test local error compilechunk print end test thanks help\n",
      "\n",
      "[Contexto 6 | Similaridade: 0.390]\n",
      "Title: invalid. Body: judge eee\n",
      "\n",
      "[Contexto 7 | Similaridade: 0.386]\n",
      "Title: line. Body: brf number crashes impacted devices lot information crash crashlytics com\n",
      "\n",
      "[Contexto 8 | Similaridade: 0.379]\n",
      "Title: bug log. Body: mar europe berlin php fatal error uncaught error call member function query null inetpub stack trace inetpub profile user showforentity object entity inetpub profile user displaytabcontentforitem object entity inetpub commonglpi displaystandardtab object entity profile user array main thrown inetpub line mar europe berlin php fatal error uncaught zend exception parseexception unknown invalid parser rule nplurals integer plural expression inetpub stack trace inetpub zend translator plural rule fromstring nplurals integ inetpub zend translator loader gettext load inetpub inetpub zend translator translator loadmessagesfromfiles mydashboard inetpub zend translator translator loadmessages mydashboard inetpub zend translator translator gettr inetpub line\n",
      "\n",
      "[Contexto 9 | Similaridade: 0.377]\n",
      "Title: line. Body: number crashes impacted devices lot information crash crashlytics com\n",
      "\n",
      "[Contexto 10 | Similaridade: 0.373]\n",
      "Title: issues. Body: new issue test\n",
      "\n",
      "[Contexto 11 | Similaridade: 0.367]\n",
      "Title: add faq. Body: answer common questions countries data data gathered language deduced report error suggest feature epurpose project etc\n",
      "\n",
      "[Contexto 12 | Similaridade: 0.366]\n",
      "Title: ent dec. Body: entero decimal entero los ejemplos dice ent dec dec talvez error asi\n",
      "\n",
      "[Contexto 13 | Similaridade: 0.361]\n",
      "Title: fix. Body: still lots problems needs thorough testing launch\n",
      "\n",
      "[Contexto 14 | Similaridade: 0.358]\n",
      "Title: adress. Body: old needs adressed properly probably useful current state code could likely used one way another nemerald adress issue since code stale branch start\n",
      "\n",
      "[Contexto 15 | Similaridade: 0.357]\n",
      "Title: void. Body: actually void data structures placeholders everything passed arguments pedrohsoares wykthor btracker nicholas arqui let found\n",
      "\n",
      "[Contexto 16 | Similaridade: 0.352]\n",
      "Title: issue. Body: bug number\n",
      "\n",
      "[Contexto 17 | Similaridade: 0.352]\n",
      "Title: issue. Body: bug number\n",
      "\n",
      "[Contexto 18 | Similaridade: 0.352]\n",
      "Title: issue. Body: bug number\n",
      "\n",
      "[Contexto 19 | Similaridade: 0.352]\n",
      "Title: issue. Body: bug number\n",
      "\n",
      "[Contexto 20 | Similaridade: 0.352]\n",
      "Title: issue. Body: bug number\n",
      "\n",
      "[Contexto 21 | Similaridade: 0.352]\n",
      "Title: issue. Body: bug number\n",
      "\n",
      "[Contexto 22 | Similaridade: 0.351]\n",
      "Title: task. Body: ronitron complete form validations registrations form done closed\n",
      "\n",
      "[Contexto 23 | Similaridade: 0.343]\n",
      "Title: tests. Body: est dommage que fichier soit vide surtout quand dans ton historique commits des trucs genre fix machin truc framework pour les tests est super bien foutu permet vraiment faire des choses assez bal zes alors sans aller jusqu tout tester encore que aide vraiment mettre moins mettre les bugs que rencontres\n",
      "\n",
      "[Contexto 24 | Similaridade: 0.340]\n",
      "Title: req. Body: restricciones tiene para hacer esas ediciones modificaciones los datos del inventario\n",
      "\n",
      "[Contexto 25 | Similaridade: 0.340]\n",
      "Title: line. Body: com number crashes impacted devices lot information crash crashlytics com\n",
      "\n",
      "[Contexto 26 | Similaridade: 0.340]\n",
      "Title: line. Body: com number crashes impacted devices lot information crash crashlytics com\n",
      "\n",
      "[Contexto 27 | Similaridade: 0.340]\n",
      "Title: line. Body: com number crashes impacted devices lot information crash crashlytics com\n",
      "\n",
      "[Contexto 28 | Similaridade: 0.339]\n",
      "Title: issue. Body: testing issue issue\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_CHARS = 800  # por documento\n",
    "\n",
    "lista_final = sorted(\n",
    "    lista_final,\n",
    "    key=lambda x: x[\"score\"],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "contexto = \"\"\n",
    "limite = 28\n",
    "\n",
    "if len(lista_final) <= limite:\n",
    "    for i in range(len(lista_final)):\n",
    "        text_limited = lista_final[i][\"text\"][:MAX_CHARS]\n",
    "\n",
    "        contexto += (\n",
    "            f\"[Contexto {i+1} | \"\n",
    "            f\"Similaridade: {lista_final[i]['score']:.03f}]\\n\"\n",
    "            f\"{text_limited}\\n\\n\"\n",
    "        )\n",
    "\n",
    "else:\n",
    "    for i in range(limite):\n",
    "        text_limited = lista_final[i][\"text\"][:MAX_CHARS]\n",
    "\n",
    "        contexto += (\n",
    "            f\"[Contexto {i+1} | \"\n",
    "            f\"Similaridade: {lista_final[i]['score']:.03f}]\\n\"\n",
    "            f\"{text_limited}\\n\\n\"\n",
    "        )\n",
    "\n",
    "print(contexto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e7a471",
   "metadata": {},
   "source": [
    "**Definir tipos de perguntas para ajustar prompt e resposta**\n",
    "\n",
    "- Dividir as perguntas em 3 tipos\n",
    "    - (A) Podem ser respondidas claramente pelo modelo. Ex: \"quais tipos\", \"quais problemas\", \"sobre o que\", \"resuma\"..\n",
    "    - (B) Podem ser respondidas com ressalvas. Ex: “mais comuns”,“mais registrados”,“principais” ..\n",
    "    - (C) O Modelo pode alucinar e dar estatísticas erradas, não recomendado para o propósito da IA. Ex: \"quantos\", \"porcentagem\", \"frequência\", \"exata quantidade\" .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "603647e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo da pergunta: QUALITATIVE\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..', 'src', 'prompts')))\n",
    "from rag_prompts import classify_question, build_direct_prompt, build_qualitative_prompt, build_out_of_scope_prompt, build_prompt\n",
    "\n",
    "QUESTION_TYPE_A = \"DIRECT\"\n",
    "QUESTION_TYPE_B = \"QUALITATIVE\" \n",
    "QUESTION_TYPE_C = \"OUT_OF_SCOPE\"\n",
    "\n",
    "question_type = classify_question(pergunta)\n",
    "print(\"Tipo da pergunta:\", question_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eba7b4",
   "metadata": {},
   "source": [
    "**Validador de prompts**\n",
    "\n",
    "- Antes de passar para LLM analisar, o validador irá verificar se a pergunta se enquadra num tópico a ser analisado ou pode ser respondido sem LLM\n",
    "- Irá atuar como Gatekeeper, reduzindo a quantidade de tokens analisados\n",
    "- Evita desperdício de Quota da LLM e redução de custo\n",
    "\n",
    "**Integração da LLM**\n",
    "\n",
    "- Estou usando Gemini devido a facilidade de obtenção de uma chave gratuita para estudantes\n",
    "- A LLM irá receber as informações retiradas do Dataset \n",
    "- Será utilizado engenharia de prompt para qualificar a análise da LLM\n",
    "- No projeto será implantado um scan de input para o usuário digitar sua propria chave api gemini e testar o programa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d63e8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existem múltiplos relatos de \"crashes\" ou falhas, frequentemente associados a dispositivos e mencionados com informações de \"crashlytics\".\n",
      "\n",
      "Também se observam menções a erros relacionados a \"insert\" (inserção), com detalhes sobre dados a serem incluídos como nomes de organização e tipos.\n",
      "\n",
      "Há também menções de erros de \"bug\" e \"issue\", algumas vezes repetidas com a palavra \"number\", sugerindo que se referem a identificadores de problemas.\n",
      "\n",
      "Outro padrão recorrente são erros relacionados a cálculo ou retorno de valores, como \"standard errors\", \"standard deviations\", \"standard deviations\", \"beta\", e \"entero decimal\".\n",
      "\n",
      "Há também erros de compilação ou de lógica em código, como problemas com \"lua function\", \"compilechunk\", \"parser rule\", e \"plural expression\".\n",
      "\n",
      "Além disso, há relatos de dados inválidos ou problemas de validação, como \"invalid\", \"parser rule nplurals integer plural expression\", e \"form validations registrations\".\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..', 'src', 'llm')))\n",
    "\n",
    "from context_validator import validate_context, static_fallback, insufficient_context_response\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from rag_prompts import build_prompt\n",
    "from gemini_client import generate_answer, answer_question\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "chave_api = os.getenv(\"GOOGLE_API_KEY\")\n",
    "resposta = answer_question(pergunta,contexto)\n",
    "print(resposta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
